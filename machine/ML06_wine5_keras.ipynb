{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2938 samples, validate on 735 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 0.3380 - acc: 0.9299 - val_loss: 0.3243 - val_acc: 0.9211\n",
      "Epoch 2/40\n",
      " - 1s - loss: 0.2800 - acc: 0.9302 - val_loss: 0.2831 - val_acc: 0.9211\n",
      "Epoch 3/40\n",
      " - 1s - loss: 0.2554 - acc: 0.9316 - val_loss: 0.2842 - val_acc: 0.9238\n",
      "Epoch 4/40\n",
      " - 1s - loss: 0.2418 - acc: 0.9316 - val_loss: 0.2884 - val_acc: 0.9211\n",
      "Epoch 5/40\n",
      " - 1s - loss: 0.2311 - acc: 0.9333 - val_loss: 0.2822 - val_acc: 0.9238\n",
      "Epoch 6/40\n",
      " - 1s - loss: 0.2243 - acc: 0.9333 - val_loss: 0.2925 - val_acc: 0.9197\n",
      "Epoch 7/40\n",
      " - 1s - loss: 0.2139 - acc: 0.9336 - val_loss: 0.3195 - val_acc: 0.9197\n",
      "Epoch 8/40\n",
      " - 1s - loss: 0.2007 - acc: 0.9374 - val_loss: 0.2980 - val_acc: 0.9224\n",
      "Epoch 9/40\n",
      " - 1s - loss: 0.1948 - acc: 0.9374 - val_loss: 0.3423 - val_acc: 0.9224\n",
      "Epoch 10/40\n",
      " - 1s - loss: 0.1920 - acc: 0.9387 - val_loss: 0.3132 - val_acc: 0.9211\n",
      "Epoch 11/40\n",
      " - 1s - loss: 0.1724 - acc: 0.9401 - val_loss: 0.3188 - val_acc: 0.9184\n",
      "Epoch 12/40\n",
      " - 1s - loss: 0.1704 - acc: 0.9418 - val_loss: 0.3712 - val_acc: 0.9170\n",
      "Epoch 13/40\n",
      " - 1s - loss: 0.1504 - acc: 0.9449 - val_loss: 0.3636 - val_acc: 0.9184\n",
      "Epoch 14/40\n",
      " - 1s - loss: 0.1379 - acc: 0.9462 - val_loss: 0.4052 - val_acc: 0.9184\n",
      "Epoch 15/40\n",
      " - 1s - loss: 0.1384 - acc: 0.9523 - val_loss: 0.3875 - val_acc: 0.9156\n",
      "Epoch 16/40\n",
      " - 1s - loss: 0.1294 - acc: 0.9510 - val_loss: 0.4146 - val_acc: 0.9102\n",
      "Epoch 17/40\n",
      " - 1s - loss: 0.1110 - acc: 0.9605 - val_loss: 0.3998 - val_acc: 0.9129\n",
      "Epoch 18/40\n",
      " - 1s - loss: 0.1125 - acc: 0.9595 - val_loss: 0.4147 - val_acc: 0.9184\n",
      "Epoch 19/40\n",
      " - 1s - loss: 0.1051 - acc: 0.9649 - val_loss: 0.3897 - val_acc: 0.8952\n",
      "Epoch 20/40\n",
      " - 1s - loss: 0.1004 - acc: 0.9670 - val_loss: 0.4001 - val_acc: 0.9075\n",
      "Epoch 21/40\n",
      " - 1s - loss: 0.0853 - acc: 0.9697 - val_loss: 0.4063 - val_acc: 0.9048\n",
      "Epoch 22/40\n",
      " - 1s - loss: 0.0828 - acc: 0.9711 - val_loss: 0.4754 - val_acc: 0.9102\n",
      "Epoch 23/40\n",
      " - 1s - loss: 0.0814 - acc: 0.9721 - val_loss: 0.4557 - val_acc: 0.9156\n",
      "Epoch 24/40\n",
      " - 1s - loss: 0.0729 - acc: 0.9741 - val_loss: 0.5806 - val_acc: 0.9048\n",
      "Epoch 25/40\n",
      " - 1s - loss: 0.0695 - acc: 0.9748 - val_loss: 0.5844 - val_acc: 0.9075\n",
      "Epoch 26/40\n",
      " - 1s - loss: 0.0588 - acc: 0.9792 - val_loss: 0.6180 - val_acc: 0.9075\n",
      "Epoch 27/40\n",
      " - 1s - loss: 0.0768 - acc: 0.9731 - val_loss: 0.5164 - val_acc: 0.9034\n",
      "Epoch 28/40\n",
      " - 1s - loss: 0.0666 - acc: 0.9769 - val_loss: 0.6301 - val_acc: 0.9007\n",
      "Epoch 29/40\n",
      " - 1s - loss: 0.0658 - acc: 0.9755 - val_loss: 0.7019 - val_acc: 0.8844\n",
      "Epoch 30/40\n",
      " - 1s - loss: 0.0584 - acc: 0.9813 - val_loss: 0.5821 - val_acc: 0.8980\n",
      "Epoch 31/40\n",
      " - 1s - loss: 0.0689 - acc: 0.9796 - val_loss: 0.5637 - val_acc: 0.9102\n",
      "Epoch 32/40\n",
      " - 1s - loss: 0.0613 - acc: 0.9803 - val_loss: 0.6723 - val_acc: 0.9048\n",
      "Epoch 33/40\n",
      " - 1s - loss: 0.0668 - acc: 0.9792 - val_loss: 0.6082 - val_acc: 0.9088\n",
      "Epoch 34/40\n",
      " - 1s - loss: 0.0404 - acc: 0.9884 - val_loss: 0.5299 - val_acc: 0.9061\n",
      "Epoch 35/40\n",
      " - 1s - loss: 0.0496 - acc: 0.9837 - val_loss: 0.6719 - val_acc: 0.8925\n",
      "Epoch 36/40\n",
      " - 1s - loss: 0.0535 - acc: 0.9830 - val_loss: 0.6608 - val_acc: 0.9116\n",
      "Epoch 37/40\n",
      " - 1s - loss: 0.0509 - acc: 0.9847 - val_loss: 0.6336 - val_acc: 0.9116\n",
      "Epoch 38/40\n",
      " - 1s - loss: 0.0406 - acc: 0.9884 - val_loss: 0.8310 - val_acc: 0.8816\n",
      "Epoch 39/40\n",
      " - 1s - loss: 0.0383 - acc: 0.9884 - val_loss: 0.6699 - val_acc: 0.9238\n",
      "Epoch 40/40\n",
      " - 1s - loss: 0.0518 - acc: 0.9854 - val_loss: 0.7079 - val_acc: 0.9143\n",
      "1225/1225 [==============================] - 0s 187us/step\n",
      "Accuracy: 0.9044897959183673\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "wine = pd.read_csv(\"./data/winequality-white.csv\",sep=\";\", encoding='utf-8')\n",
    "     \n",
    "#1. 데이터\n",
    "\n",
    "y=wine['quality']\n",
    "x=wine.drop(\"quality\",axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x)\n",
    "x=scaler.transform(x)\n",
    "\n",
    "new_list=[]\n",
    "\n",
    "for v in list(y):\n",
    "    if v <= 4:\n",
    "        new_list += [0]\n",
    "    elif v<= 7:\n",
    "        new_list += [1]\n",
    "    else:\n",
    "        new_list += [2]\n",
    "\n",
    "y=new_list\n",
    "y=np.array(y)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.75)\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu',input_shape=(11,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# #3. 훈련\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=4,epochs=40,verbose=2, validation_split=0.2)\n",
    "\n",
    "res= model.evaluate(x_test, y_test,batch_size=4)\n",
    "print('Accuracy:', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aws_neuron_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-aws_neuron_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
